## Advanced ETL Pipeline
ğŸš€ A robust ETL (Extract, Transform, Load) pipeline in Python that cleans, transforms, and loads data into a PostgreSQL database.

## ğŸ“Œ Features
- âœ… Extract messy data from CSV files.
- âœ… Transform by fixing incorrect values, handling duplicates, and cleaning data.
- âœ… Load clean data into a PostgreSQL database.
- âœ… Data Quality Report generated for tracking fixes.
- âœ… Handles Missing Data, Fixes Incorrect Dates, Validates Emails, and Removes Duplicates.

## ğŸ“‚ Folder Structure
- bash
- Copy
- Edit
- /ETL-Project

  â”‚â”€â”€ advanced_etl_pipeline.py  # Main ETL script
  
  â”‚â”€â”€ raw_messy_data.csv        # Sample raw data
  
  â”‚â”€â”€ data_quality_report.csv   # Auto-generated quality report
  
  â”‚â”€â”€ requirements.txt          # Dependencies
  
  â”‚â”€â”€ README.md                 # Project documentation
  

## ğŸ›  Installation

1ï¸âƒ£ Clone the Repository
- git clone https://github.com/yourusername/ETL-Project.git
- cd ETL-Project

2ï¸âƒ£ Create & Activate Virtual Environment (Optional)
- python3 -m venv venv
- source venv/bin/activate  # On Mac/Linux
- venv\Scripts\activate     # On Windows
- Refer general_info.txt for more information
  
3ï¸âƒ£ Install Dependencies
- pip install -r requirements.txt
- [Postgres Database download](https://www.enterprisedb.com/downloads/postgres-postgresql-downloads)
  
## ğŸ“ Configuration
- Update Database Credentials
- Modify the database URI inside advanced_etl_pipeline.py:
- db_uri = "postgresql://postgres:yourpassword@localhost:5433/yourdatabase"

## ğŸš€ Running the ETL Pipeline
python advanced_etl_pipeline.py 

ğŸ” Example Output
Raw Data:
... (original messy data)

<img width="545" alt="image" src="https://github.com/user-attachments/assets/916285f9-2cf5-440e-92bc-6786d5a42ff2" />


Transformed Data:
... (cleaned data)

<img width="854" alt="image" src="https://github.com/user-attachments/assets/b4a7adbd-5a11-4a38-ac98-07113bd3befd" />

Cleaned data loaded successfully.
Data quality report saved as data_quality_report.csv

<img width="781" alt="image" src="https://github.com/user-attachments/assets/b0a94d24-a7c0-4c2f-8beb-48abde1c2a60" />


## ğŸ“Š Data Cleaning Rules

<img width="781" alt="image" src="https://github.com/user-attachments/assets/d1b7f3d2-8d5f-4289-af47-87e083b40ab1" />


## ğŸ”— Dependencies
- pandas
- sqlalchemy
- psycopg2
- datetime
- Install them using: pip install pandas sqlalchemy psycopg2

## ğŸ¯ Final Output: ##
After running the ETL pipeline, you will see three key outputs:
1. Transformed Data (Terminal Output)
- Duplicates removed
- City names corrected (e.g., Dehli â†’ Delhi)
- Invalid dates replaced (e.g., 2024-14-32 â†’ 2000-01-01)
- Negative amounts converted to positive
- Invalid emails removed
  
2. Data Loaded Successfully
   - Confirmation that the data is stored in the PostgreSQL database
   - SELECT * FROM cleaned_data;
     <img width="758" alt="image" src="https://github.com/user-attachments/assets/89a26350-35a0-458b-be03-7f3a5c7bb9fb" />

3. Data Quality Report â€“ A CSV file summarizing all transformations and issues fixed.
- âœ”ï¸ Clean data, stored, and ready for analysis! ğŸš€

## ğŸ¯ Future Enhancements
- ğŸ“Œ Add support for different databases (MySQL, SQLite).
- ğŸ“Œ Implement a streaming ETL pipeline using Apache Kafka.
- ğŸ“Œ Deploy as a Dockerized microservice.

## ğŸ¤ Contributing
Want to contribute? Fork the repository, create a branch, and submit a pull request! ğŸš€

## ğŸ“œ License
This project is licensed under the MIT License.

## ğŸ“« Connect with Me
- [LinkedIn](https://www.linkedin.com/in/sanjeev-kumar-singh-sks-b7b612ba/)
- [Twitter](https://x.com/iamsks267)
- [Email](mailto:sanjeevksingh267@gmail.com)
